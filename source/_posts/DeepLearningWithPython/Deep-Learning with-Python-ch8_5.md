---
categories:
- Machine Learning
- Deep Learning with Python
date: 2020-08-24 21:16:34
tag:
- Machine Learning
- Deep Learning
title: Pythonæ·±åº¦å­¦ä¹ ä¹‹GAN
---

# Deep Learning with Python

è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» [GitHub](https://github.com/cdfmlr/Deep-Learning-with-Python-Notebooks) æˆ– [Gitee](https://gitee.com/cdfmlr/Deep-Learning-with-Python-Notebooks) æ‰¾åˆ°åŸå§‹çš„ `.ipynb` ç¬”è®°æœ¬ã€‚

ä½ å¯ä»¥å»[è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡](https://livebook.manning.com/book/deep-learning-with-python)(è‹±æ–‡)ã€‚è¿™æœ¬ä¹¦çš„ä½œè€…ä¹Ÿç»™å‡ºäº†é…å¥—çš„ [Jupyter notebooks](https://github.com/fchollet/deep-learning-with-python-notebooks)ã€‚

æœ¬æ–‡ä¸º **ç¬¬8ç«   ç”Ÿæˆå¼æ·±åº¦å­¦ä¹ ** (Chapter 8. *Generative deep learning*) çš„ç¬”è®°ä¹‹ä¸€ã€‚

[TOC]


## 8.5 Introduction to generative adversarial networks

> ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œç®€ä»‹

GANï¼Œä¸­æ–‡æ˜¯~~æ·¦~~ï¼Œé”™äº†ï¼Œç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ(Generative Adversarial Network)ã€‚å’Œ VAE ä¸€æ ·ï¼Œæ˜¯ç”¨æ¥å­¦ä¹ å›¾åƒçš„æ½œåœ¨ç©ºé—´çš„ã€‚è¿™ä¸œè¥¿å¯ä»¥ä½¿ç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒâ€œåœ¨ç»Ÿè®¡ä¸Šâ€åˆ«æ— äºŒè‡´ï¼Œè¯´äººè¯å°±æ˜¯ï¼Œç”Ÿæˆçš„å›¾åƒç›¸å½“é€¼çœŸã€‚ä½†ä¸ VAE ä¸åŒï¼ŒGAN çš„æ½œåœ¨ç©ºé—´æ— æ³•ä¿è¯å…·æœ‰æœ‰æ„ä¹‰çš„ç»“æ„ï¼Œå¹¶ä¸”æ˜¯ä¸è¿ç»­çš„ã€‚

GAN ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š

- ç”Ÿæˆå™¨ç½‘ç»œ(generator network)ï¼šè¾“å…¥ä¸€ä¸ªéšæœºå‘é‡(æ½œåœ¨ç©ºé—´ä¸­çš„ä¸€ä¸ªéšæœºç‚¹)ï¼Œå¹¶å°†å…¶è§£ç ä¸ºå›¾åƒã€‚
- åˆ¤åˆ«å™¨ç½‘ç»œ(discriminator network)ï¼šè¾“å…¥ä¸€å¼ å›¾åƒ(çœŸå®çš„æˆ–ç”Ÿæˆå™¨ç”»çš„)ï¼Œé¢„æµ‹è¯¥å›¾åƒæ˜¯çœŸå®çš„è¿˜æ˜¯ç”±ç”Ÿæˆå™¨ç½‘ç»œåˆ›å»ºçš„ã€‚ï¼ˆåˆ¤åˆ«å™¨ç½‘ç»œä¹Ÿå«ã€Œå¯¹æ‰‹ã€ï¼Œadversaryï¼‰

è®­ç»ƒ GAN çš„ç›®çš„æ˜¯ä½¿ã€Œç”Ÿæˆå™¨ç½‘ç»œã€èƒ½å¤Ÿæ¬ºéª—ã€Œåˆ¤åˆ«å™¨ç½‘ç»œã€ã€‚

ç›´è§‚ç†è§£ GAN æ˜¯ä¸€ä¸ªå¾ˆåŠ±å¿—çš„æ•…äº‹ï¼šå°±æ˜¯è¯´æœ‰ä¸¤ä¸ªäººï¼Œä¸€ä¸ªä¼ªé€ è€…ï¼Œä¸€ä¸ªé‰´å®šå¸ˆã€‚ä¼ªé€ è€…ä»¿é€ å¤§å¸ˆçš„ç”»ï¼Œç„¶åæŠŠè‡ªå·±çš„ä»¿åˆ¶å“æ··åœ¨çœŸè¿¹é‡Œäº¤ç»™é‰´å®šå¸ˆé‰´å®šï¼Œé‰´å®šå¸ˆè¯„ä¼°æ¯ä¸€å¹…ç”»çš„çœŸä¼ªï¼Œä¸€æ ·çœ‹ç©¿äº†å“ªäº›æ˜¯ä¼ªé€ çš„ã€‚å¥½å¿ƒçš„é‰´å®šå¸ˆåé¦ˆäº†ä¼ªé€ è€…ï¼Œå‘Šè¯‰ä»–çœŸè¿¹æœ‰å“ªäº›ç‰¹å¾ã€‚ä¼ªé€ è€…æ ¹æ®é‰´å®šå¸ˆçš„æ„è§ï¼Œä¸€æ­¥æ­¥æå‡è‡ªå·±çš„ä»¿é€ èƒ½åŠ›ã€‚ä¸¤äººä¸åŒå…¶çƒ¦åœ°é‡å¤è¿™ä¸ªè¿‡ç¨‹ï¼Œä¼ªé€ è€…å˜å¾—è¶Šæ¥è¶Šæ“…é•¿å¤åˆ¶å¤§å¸ˆçš„ç”»ï¼Œé‰´å®šå¸ˆä¹Ÿè¶Šæ¥è¶Šæ“…é•¿æ‰¾å‡ºå‡ç”»ã€‚åˆ°æœ€åï¼Œä¼ªé€ è€…é€ å‡ºäº†ä¸€æ‰¹é‰´å®šå¸ˆä¹Ÿæ— å¯æŒ‘å‰”çš„â€œä»¿åˆ¶æ­£å“â€ã€‚

![ç”Ÿæˆå™¨å°†éšæœºæ½œåœ¨å‘é‡è½¬æ¢æˆå›¾åƒï¼Œåˆ¤åˆ«å™¨è¯•å›¾åˆ†è¾¨çœŸå®å›¾åƒä¸ç”Ÿæˆå›¾åƒã€‚ç”Ÿæˆå™¨çš„è®­ç»ƒæ˜¯ä¸ºäº†æ¬ºéª—åˆ¤åˆ«å™¨](https://tva1.sinaimg.cn/large/007S8ZIlgy1ghva0rve82j31ec0tcthm.jpg)

GAN çš„è®­ç»ƒæ–¹å¼å¾ˆç‰¹æ®Šï¼Œå®ƒçš„ä¼˜åŒ–æœ€å°å€¼æ˜¯ä¸å›ºå®šçš„ã€‚æˆ‘ä»¬é€šå¸¸çš„ã€Œæ¢¯åº¦ä¸‹é™ã€æ˜¯æ²¿ç€é™æ€çš„æŸå¤±åœ°å½¢æ»šä¸‹å±±ï¼Œä½† GAN è®­ç»ƒæ—¶æ¯ä¸‹å±±ä¸€æ­¥éƒ½ä¼šå¯¹æ•´ä¸ªåœ°å½¢é€ æˆæ”¹å˜ã€‚å®ƒæ˜¯ä¸€ä¸ªåŠ¨æ€ç³»ç»Ÿï¼Œå…¶æœ€ä¼˜åŒ–è¿‡ç¨‹æ˜¯ä¸¤è‚¡åŠ›é‡ä¹‹é—´çš„å¹³è¡¡ã€‚æ‰€ä»¥ï¼ŒGAN å¾ˆéš¾è®­ç»ƒã€‚æƒ³è¦è®© GAN æ­£å¸¸è¿è¡Œï¼Œéœ€è¦è¿›è¡Œå¤§é‡çš„æ¨¡å‹æ„å»ºã€è¶…å‚æ•°è°ƒèŠ‚å·¥ä½œã€‚

### æ·±åº¦å·ç§¯ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ

æˆ‘ä»¬æ¥å°è¯•ç”¨ Keras å®ç°æœ€æœ€æœ€ç®€å•çš„ GANã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¼šåšä¸€ä¸ª**æ·±åº¦å·ç§¯ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ**ï¼ˆdeep convolutional GANï¼ŒDCGANï¼‰ï¼Œè¿™ç§ä¸œè¥¿çš„ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨éƒ½æ˜¯æ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œã€‚

æˆ‘ä»¬å°†ç”¨ CIFAR10 æ•°æ®é›†ä¸­â€œfrogâ€ç±»åˆ«çš„å›¾åƒè®­ç»ƒ DCGANã€‚è¿™ä¸ªæ•°æ®é›†åŒ…å« 50000 å¼  32Ã—32 çš„ RGB å›¾åƒï¼Œè¿™äº›å›¾åƒå±äº 10 ä¸ªç±»åˆ«(æ¯ä¸ªç±»åˆ« 5000 å¼ å›¾åƒ)ã€‚

#### å®ç°æµç¨‹

1. `generator` ç½‘ç»œå°†å½¢çŠ¶ä¸º `(latent_dim,)` çš„å‘é‡æ˜ å°„åˆ°å½¢çŠ¶ä¸º `(32, 32, 3)` çš„å›¾åƒã€‚
2. `discriminator` ç½‘ç»œå°†å½¢çŠ¶ä¸º `(32, 32, 3)` çš„å›¾åƒæ˜ å°„åˆ°ä¸€ä¸ªäºŒè¿›åˆ¶å¾—åˆ†(a binary score)ï¼Œç”¨äºè¯„ä¼°å›¾åƒä¸ºçœŸçš„æ¦‚ç‡ã€‚
3. `gan` ç½‘ç»œå°† `generator` å’Œ `discriminator` è¿æ¥åœ¨ä¸€èµ·: `gan(x) = discriminator(generator(x))`ã€‚è¿™ä¸ªç½‘ç»œæ˜¯å°†æ½œåœ¨å‘é‡æ˜ å°„åˆ°åˆ¤åˆ«å™¨çš„è¯„ä¼°ç»“æœã€‚
4. ä½¿ç”¨å¸¦æœ‰ `"real"` æˆ– `"fake"` æ ‡ç­¾çš„çœŸå‡å›¾åƒæ ·æœ¬æ¥è®­ç»ƒåˆ¤åˆ«å™¨ï¼Œç”¨å¸¸è§„è®­ç»ƒæ™®é€šçš„å›¾åƒåˆ†ç±»æ¨¡å‹çš„æ–¹æ³•ã€‚
5. ä¸ºäº†è®­ç»ƒç”Ÿæˆå™¨ï¼Œä½¿ç”¨ `gan` æ¨¡å‹çš„æŸå¤±ç›¸å¯¹äºç”Ÿæˆå™¨æƒé‡çš„æ¢¯åº¦ã€‚åœ¨æ¯ä¸€æ­¥éƒ½è¦å‘ã€Œè®©åˆ¤åˆ«å™¨æ›´æœ‰å¯èƒ½å°†ç”Ÿæˆå™¨è§£ç çš„å›¾åƒåˆ’åˆ†ä¸ºâ€œçœŸâ€ã€ç§»åŠ¨ç”Ÿæˆå™¨çš„æƒé‡ï¼Œå³è®­ç»ƒç”Ÿæˆå™¨æ¥æ¬ºéª—åˆ¤åˆ«å™¨ã€‚

#### å®ç”¨æŠ€å·§

è®­ç»ƒå’Œè°ƒèŠ‚ GAN çš„è¿‡ç¨‹éå¸¸å›°éš¾ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦è®°ä½ä¸€äº›å‰äººæ€»ç»“å‡ºçš„å®ç”¨æŠ€å·§ã€‚è¿™äº›æŠ€å·§ä¸€èˆ¬å¾ˆæœ‰ç”¨ï¼Œä½†å¹¶ä¸èƒ½é€‚ç”¨äºæ‰€æœ‰æƒ…å†µã€‚è¿™äº›ä¸œè¥¿éƒ½æ²¡æœ‰ç†è®ºä¾æ®ï¼Œéƒ½æ˜¯ç„å­¦ï¼Œæ‰€ä»¥ä¸è§£é‡Šç›´æ¥å†™ç»“è®ºï¼š

- ä½¿ç”¨ tanh ä½œä¸ºç”Ÿæˆå™¨æœ€åä¸€å±‚çš„æ¿€æ´»ï¼Œè€Œä¸ç”¨ sigmoidã€‚
- ä½¿ç”¨æ­£æ€åˆ†å¸ƒ(é«˜æ–¯åˆ†å¸ƒ)å¯¹æ½œåœ¨ç©ºé—´ä¸­çš„ç‚¹è¿›è¡Œé‡‡æ ·ï¼Œè€Œä¸ç”¨å‡åŒ€åˆ†å¸ƒã€‚
- éšæœºæ€§èƒ½å¤Ÿæé«˜ç¨³å¥æ€§ã€‚GAN è®­ç»ƒæ—¶å¯èƒ½ä»¥å„ç§æ–¹å¼â€œå¡ä½â€(è¾¾åˆ°é”™è¯¯çš„åŠ¨æ€å¹³è¡¡)ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥éšæœºæ€§æœ‰åŠ©äºé˜²æ­¢å‡ºç°è¿™ç§æƒ…å†µï¼Œå¼•å…¥éšæœºæ€§çš„æ–¹å¼æœ‰ä¸¤ç§ï¼š
    1. åœ¨åˆ¤åˆ«å™¨ä¸­ä½¿ç”¨ dropout;
    2. å‘åˆ¤åˆ«å™¨çš„æ ‡ç­¾æ·»åŠ éšæœºå™ªå£°;
- ç¨€ç–çš„æ¢¯åº¦ä¼šå¦¨ç¢ GAN çš„è®­ç»ƒã€‚ã€Œæœ€å¤§æ± åŒ–è¿ç®—ã€å’Œ ã€ŒReLU æ¿€æ´»ã€å¯èƒ½å¯¼è‡´æ¢¯åº¦ç¨€ç–ï¼Œæ‰€ä»¥æ¨èï¼š
    1. ä½¿ç”¨ã€Œæ­¥è¿›å·ç§¯ã€ä»£æ›¿ã€Œæœ€å¤§æ± åŒ–ã€æ¥è¿›è¡Œä¸‹é‡‡æ ·;
    2. ä½¿ç”¨ LeakyReLU å±‚æ¥ä»£æ›¿ ReLU æ¿€æ´»;
- åœ¨ç”Ÿæˆçš„å›¾åƒä¸­ï¼Œå¸¸ä¼šè§åˆ°æ£‹ç›˜çŠ¶ä¼ªå½±ï¼Œè¿™æ˜¯ç”±äºç”Ÿæˆå™¨ä¸­åƒç´ ç©ºé—´è¦†ç›–ä¸å‡åŒ€ã€‚è§£å†³è¿™ä¸ªé—®é¢˜çš„åŠæ³•æ˜¯ï¼šæ¯å½“åœ¨ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä¸­éƒ½ä½¿ç”¨æ­¥è¿› Conv2DTranpose æˆ– Conv2D æ—¶ï¼Œå†…æ ¸å¤§å°è¦èƒ½å¤Ÿè¢«æ­¥å¹…æ•´é™¤ã€‚



ç”±äºæ­¥å¹…å¤§å°å’Œå†…æ ¸å¤§å°ä¸åŒ¹é…è€Œå¯¼è‡´çš„æ£‹ç›˜çŠ¶ä¼ªå½±ç¤ºä¾‹å›¾:

![ç”±äºæ­¥å¹…å¤§å°å’Œå†…æ ¸å¤§å°ä¸åŒ¹é…è€Œå¯¼è‡´çš„æ£‹ç›˜çŠ¶ä¼ªå½±](https://tva1.sinaimg.cn/large/007S8ZIlgy1ghvayd7ipwj31560ggazl.jpg)

#### ç”Ÿæˆå™¨çš„å®ç°

å¼€å§‹æ„å»ºå¹´è½»äººçš„ç¬¬ä¸€ä¸ª GAN äº†ï¼ï¼

é¦–å…ˆå¼€å‘ generator æ¨¡å‹ï¼šå°†æ¥è‡ªæ½œåœ¨ç©ºé—´çš„å‘é‡è½¬æ¢ä¸ºä¸€å¼ å€™é€‰å›¾åƒã€‚

ä¸ºäº†é¿å…è®­ç»ƒæ—¶â€œå¡ä½â€ï¼Œåœ¨åˆ¤åˆ«å™¨å’Œç”Ÿæˆå™¨ä¸­éƒ½ä½¿ç”¨ dropoutã€‚


```python
# GAN ç”Ÿæˆå™¨ç½‘ç»œ

from tensorflow import keras
from tensorflow.keras import layers
import numpy as np

height = 32
width = 32
channels = 3

latent_dim = 32

generator_input = keras.Input(shape=(latent_dim,))

# å°†è¾“å…¥è½¬æ¢ä¸ºå¤§å°ä¸º 16Ã—16 çš„ 128 ä¸ªé€šé“çš„ç‰¹å¾å›¾
x = layers.Dense(128 * 16 * 16)(generator_input)
x = layers.LeakyReLU()(x)
x = layers.Reshape((16, 16, 128))(x)

x = layers.Conv2D(256, 5, padding='same')(x)
x = layers.LeakyReLU()(x)

# ä¸Šé‡‡æ ·ä¸º 32Ã—32
x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)
x = layers.LeakyReLU()(x)

x = layers.Conv2D(256, 5, padding='same')(x)
x = layers.LeakyReLU()(x)
x = layers.Conv2D(256, 5, padding='same')(x)
x = layers.LeakyReLU()(x)

# ç”Ÿæˆå¤§å°ä¸º 32Ã—32 çš„ç‰¹å¾å›¾(CIFAR10 å›¾åƒçš„å½¢çŠ¶)
x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)

generator = keras.models.Model(generator_input, x)
generator.summary()
```

    Model: "functional_1"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_1 (InputLayer)         [(None, 32)]              0         
    _________________________________________________________________
    dense (Dense)                (None, 32768)             1081344   
    _________________________________________________________________
    leaky_re_lu (LeakyReLU)      (None, 32768)             0         
    _________________________________________________________________
    reshape (Reshape)            (None, 16, 16, 128)       0         
    _________________________________________________________________
    conv2d (Conv2D)              (None, 16, 16, 256)       819456    
    _________________________________________________________________
    leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         
    _________________________________________________________________
    conv2d_transpose (Conv2DTran (None, 32, 32, 256)       1048832   
    _________________________________________________________________
    leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         
    _________________________________________________________________
    conv2d_1 (Conv2D)            (None, 32, 32, 256)       1638656   
    _________________________________________________________________
    leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         
    _________________________________________________________________
    conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   
    _________________________________________________________________
    leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         
    _________________________________________________________________
    conv2d_3 (Conv2D)            (None, 32, 32, 3)         37635     
    =================================================================
    Total params: 6,264,579
    Trainable params: 6,264,579
    Non-trainable params: 0
    _________________________________________________________________


#### åˆ¤åˆ«å™¨çš„å®ç°

æ¥ä¸‹æ¥ï¼Œå¼€å‘ discriminator æ¨¡å‹ï¼Œè¾“å…¥ä¸€å¼ å›¾åƒ(çœŸå®çš„æˆ–åˆæˆçš„)ï¼Œå°†å…¶åˆ’åˆ†ä¸ºã€ŒçœŸã€ï¼ˆæ¥è‡ªè®­ç»ƒé›†çš„çœŸå®å›¾åƒï¼‰æˆ–ã€Œå‡ã€ï¼ˆç”Ÿæˆå™¨ç”»çš„å›¾åƒï¼‰ã€‚


```python
# GAN åˆ¤åˆ«å™¨ç½‘ç»œ

discriminator_input = layers.Input(shape=(height, width, channels))

x = layers.Conv2D(128, 3)(discriminator_input)
x = layers.LeakyReLU()(x)

x = layers.Conv2D(128, 4, strides=2)(x)
x = layers.LeakyReLU()(x)

x = layers.Conv2D(128, 4, strides=2)(x)
x = layers.LeakyReLU()(x)

x = layers.Conv2D(128, 4, strides=2)(x)
x = layers.LeakyReLU()(x)

x = layers.Flatten()(x)
x = layers.Dropout(0.4)(x)

x = layers.Dense(1, activation='sigmoid')(x)

discriminator = keras.models.Model(discriminator_input, x)
discriminator.summary()

discriminator_optimizer = keras.optimizers.RMSprop(
    lr=0.0008,
    clipvalue=1.0,
    decay=1e-8)

discriminator.compile(optimizer=discriminator_optimizer,
                      loss='binary_crossentropy')
```

    Model: "functional_3"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    input_2 (InputLayer)         [(None, 32, 32, 3)]       0         
    _________________________________________________________________
    conv2d_4 (Conv2D)            (None, 30, 30, 128)       3584      
    _________________________________________________________________
    leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 128)       0         
    _________________________________________________________________
    conv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    
    _________________________________________________________________
    leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         
    _________________________________________________________________
    conv2d_6 (Conv2D)            (None, 6, 6, 128)         262272    
    _________________________________________________________________
    leaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 128)         0         
    _________________________________________________________________
    conv2d_7 (Conv2D)            (None, 2, 2, 128)         262272    
    _________________________________________________________________
    leaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 128)         0         
    _________________________________________________________________
    flatten (Flatten)            (None, 512)               0         
    _________________________________________________________________
    dropout (Dropout)            (None, 512)               0         
    _________________________________________________________________
    dense_1 (Dense)              (None, 1)                 513       
    =================================================================
    Total params: 790,913
    Trainable params: 790,913
    Non-trainable params: 0
    _________________________________________________________________


#### å¯¹æŠ—ç½‘ç»œ

æœ€åï¼Œè®¾ç½® GANï¼Œå°†ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨è¿æ¥åœ¨ä¸€èµ·ï¼Œå°†æ½œåœ¨ç©ºé—´çš„ç‚¹è½¬æ¢ä¸ºä¸€ä¸ªçœŸæˆ–å‡çš„åˆ†ç±»åˆ¤æ–­ã€‚

è¿™ä¸ªæ¨¡å‹è®­ç»ƒæ—¶ï¼Œéœ€è¦å°†ã€Œåˆ¤åˆ«å™¨ã€å†»ç»“(ä½¿ä¹‹ä¸å¯è¢«è®­ç»ƒ)ï¼Œåªè®©ã€Œç”Ÿæˆå™¨ã€å‘ã€Œæé«˜æ¬ºéª—åˆ¤åˆ«å™¨çš„èƒ½åŠ›ã€çš„æ–¹å‘ç§»åŠ¨ã€‚

è®­ç»ƒ gan æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„å…¨éƒ¨éƒ½æ˜¯â€œçœŸå®å›¾åƒâ€çš„æ ‡ç­¾ï¼Œæ‰€ä»¥å¦‚æœåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥å¯¹ã€Œåˆ¤åˆ«å™¨ã€çš„æƒé‡è¿›è¡Œæ›´æ–°ï¼Œè®­ç»ƒä¼šä½¿å¾—åˆ¤åˆ«å™¨å§‹ç»ˆé¢„æµ‹â€œçœŸâ€ã€‚


```python
# å¯¹æŠ—ç½‘ç»œ

discriminator.trainable = False    # è¿™ä¸ªåªä¼šä½œç”¨äº gan

gan_input = keras.Input(shape=(latent_dim,))
gan_output = discriminator(generator(gan_input))
gan = keras.models.Model(gan_input, gan_output)

gan_optimizer = keras.optimizers.RMSprop(
    lr=0.0004,
    clipvalue=1.0,
    decay=1e-8)
gan.compile(optimizer=gan_optimizer,
            loss='binary_crossentropy')
```

#### è®­ç»ƒ DCGAN

è®­ç»ƒå¾ªç¯çš„æµç¨‹å¦‚ä¸‹:

1. ä»æ½œåœ¨ç©ºé—´ä¸­æŠ½å–éšæœºçš„ç‚¹(éšæœºå™ªå£°)ã€‚
2. æŠŠè¿™ä¸ªéšæœºå™ªå£°ç»™ generator ç”Ÿæˆå›¾åƒã€‚
3. å°†ç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒæ··åˆã€‚
4. ä½¿ç”¨è¿™äº›æ··åˆåçš„å›¾åƒä»¥åŠç›¸åº”çš„æ ‡ç­¾(çœŸå®å›¾åƒä¸ºâ€œçœŸâ€ï¼Œç”Ÿæˆå›¾åƒä¸ºâ€œå‡â€)æ¥è®­ç»ƒ discriminatorã€‚
5. åœ¨æ½œåœ¨ç©ºé—´ä¸­éšæœºæŠ½å–æ–°çš„ç‚¹ã€‚
6. ä½¿ç”¨è¿™äº›éšæœºå‘é‡ä»¥åŠå…¨éƒ¨æ˜¯ã€ŒçœŸå®å›¾åƒã€çš„æ ‡ç­¾æ¥è®­ç»ƒganã€‚

å…·ä½“çš„ä»£ç å®ç°ï¼š


```python
# GAN çš„è®­ç»ƒã€

import os
import time
from tensorflow.keras.preprocessing import image

# å¯¼å…¥ CIFAR10 æ•°æ®
(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()
# é€‰å‡ºé’è›™ğŸ¸çš„å›¾ç‰‡
x_train = x_train[y_train.flatten() == 6]

x_train = x_train.reshape(
    (x_train.shape[0],) + (height, width, channels)
).astype('float32') / 255.


iterations = 10000
batch_size = 20
save_dir = 'gan_save'

start = 0
for step in range(iterations+1):
    start_time = time.time()
    
    # éšæœºé‡‡æ ·æ½œåœ¨ç‚¹
    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))
    
    # ç”Ÿæˆå›¾åƒ
    generated_images = generator.predict(random_latent_vectors)
    
    # é€‰å–çœŸå®å›¾åƒ
    stop = start + batch_size
    real_images = x_train[start: stop]
    
    # åˆå¹¶ç”Ÿæˆã€çœŸå®å›¾åƒï¼Œç»™å‡ºæ ‡ç­¾
    combined_images = np.concatenate([generated_images, real_images])
    labels = np.concatenate([np.ones((batch_size, 1)),
                             np.zeros((batch_size, 1))])
    labels += 0.05 * np.random.random(labels.shape)  # å‘æ ‡ç­¾ä¸­æ·»åŠ éšæœºå™ªå£°
    
    # è®­ç»ƒåˆ¤åˆ«å™¨
    d_loss = discriminator.train_on_batch(combined_images, labels)
    
    # éšæœºé‡‡æ ·æ½œåœ¨ç‚¹
    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))
    
    misleading_targets = np.zeros((batch_size, 1))  # è°ç§°å…¨éƒ¨éƒ½æ˜¯çœŸå®å›¾ç‰‡
    
    # é€šè¿‡ gan æ¨¡å‹è®­ç»ƒç”Ÿæˆå™¨
    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)
    
    end_time = time.time()
    
    start += batch_size
    if start > len(x_train) - batch_size:
        start = 0
        
    if step % 50 == 0:
        gan.save_weights('gan.h5')
        
        print(f'step {step}: discriminator loss: {d_loss}, adversarial loss: {a_loss}')
        
        img = image.array_to_img(generated_images[0] * 255., scale=False)
        img.save(os.path.join(save_dir, f'generated_frog_{step}.png'))
        
        img = image.array_to_img(real_images[0] * 255., scale=False)
        img.save(os.path.join(save_dir, f'real_frog_{step}.png'))
    else:
        time_cost = end_time - start_time
        time_eta = time_cost * (iterations - step)
        print(f'{step}/{iterations}: {time_cost:.2f}s - ETA: {time_eta:.0f}s', end='\r')
        
```

    step 0: discriminator loss: 0.6944685578346252, adversarial loss: 0.7566524744033813
    ...
    step 500: discriminator loss: 0.7020201683044434, adversarial loss: 0.7446410059928894
    ...
    step 1000: discriminator loss: 0.7096449136734009, adversarial loss: 0.752526581287384


æœ€åè¾“å‡ºçš„å›¾åƒï¼š

![æœ€åè¾“å‡ºçš„å›¾åƒ](https://tva1.sinaimg.cn/large/007S8ZIlgy1gi27n2ulptj300w00w0si.jpg)

æ•ˆæœç›¸å½“å·®ã€‚è¿™ä¸ªä¸œè¥¿è®­ç»ƒæ¶ˆè€—å¤ªå¤§äº†ï¼Œåˆæ˜¯ CPU åŠé€€ï¼Œæˆ‘åªè·‘äº† 1000 è½®ï¼Œè¿˜å¤ªå°‘äº†ã€‚ã€‚ã€‚ä¸æ„§ä¸ºå…¨ä¹¦æœ€åä¸€é¢˜ï¼Œå‹è½´ï¼Œè¿™å°é’è›™å›¾æˆ‘ä¸è¦äº†ã€‚ğŸ˜‚
