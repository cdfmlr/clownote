---
categories:
- Machine Learning
- Deep Learning with Python
date: 2020-08-23 17:48:34
tag:
- Machine Learning
- Deep Learning
title: Pythonæ·±åº¦å­¦ä¹ ä¹‹VAE
---

# Deep Learning with Python

è¿™ç¯‡æ–‡ç« æ˜¯æˆ‘å­¦ä¹ ã€ŠDeep Learning with Pythonã€‹(ç¬¬äºŒç‰ˆï¼ŒFranÃ§ois Chollet è‘—) æ—¶å†™çš„ç³»åˆ—ç¬”è®°ä¹‹ä¸€ã€‚æ–‡ç« çš„å†…å®¹æ˜¯ä»  Jupyter notebooks è½¬æˆ Markdown çš„ï¼Œä½ å¯ä»¥å» [GitHub](https://github.com/cdfmlr/Deep-Learning-with-Python-Notebooks) æˆ– [Gitee](https://gitee.com/cdfmlr/Deep-Learning-with-Python-Notebooks) æ‰¾åˆ°åŸå§‹çš„ `.ipynb` ç¬”è®°æœ¬ã€‚

ä½ å¯ä»¥å»[è¿™ä¸ªç½‘ç«™åœ¨çº¿é˜…è¯»è¿™æœ¬ä¹¦çš„æ­£ç‰ˆåŸæ–‡](https://livebook.manning.com/book/deep-learning-with-python)(è‹±æ–‡)ã€‚è¿™æœ¬ä¹¦çš„ä½œè€…ä¹Ÿç»™å‡ºäº†é…å¥—çš„ [Jupyter notebooks](https://github.com/fchollet/deep-learning-with-python-notebooks)ã€‚

æœ¬æ–‡ä¸º **ç¬¬8ç«   ç”Ÿæˆå¼æ·±åº¦å­¦ä¹ ** (Chapter 8. *Generative deep learning*) çš„ç¬”è®°ä¹‹ä¸€ã€‚

[TOC]


## 8.4 Generating images with variational autoencoders

> ç”¨å˜åˆ†è‡ªç¼–ç å™¨ç”Ÿæˆå›¾åƒ

å‰ä¸¤ç¯‡ä»‹ç»çš„ DeepDream å’Œ Neural Style Transfer éƒ½åªæ˜¯æœ‰é™åœ°â€œä¿®æ”¹â€ç°æœ‰ä½œå“ã€‚è€Œä¸‹é¢æˆ‘ä»¬è¦ä»‹ç»åœ° GAN å’Œ VAE åˆ™æ˜¯æ›´åŠ å¯Œæœ‰åˆ›é€ æ€§çš„ï¼Œè¿™ä¸¤ç§æŠ€æœ¯éƒ½æ˜¯ä»å›¾åƒçš„æ½œåœ¨ç©ºé—´ä¸­é‡‡æ ·ï¼Œå¹¶åˆ›å»ºå…¨æ–°å›¾åƒæˆ–ç¼–è¾‘ç°æœ‰å›¾åƒã€‚

- VAEï¼šå˜åˆ†è‡ªç¼–ç å™¨(Variational AutoEncoder)
- GANï¼šç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ(Generative Adversarial Network)


### ä»æ½œåœ¨ç©ºé—´é‡‡æ ·

æ½œåœ¨ç©ºé—´(latent space)æ˜¯ä¸€ä¸ªå‘é‡ç©ºé—´ï¼Œå…¶ä¸­ä»»æ„ç‚¹éƒ½å¯ä»¥è¢«æ˜ å°„ä¸ºä¸€å¼ é€¼çœŸçš„å›¾åƒã€‚è€Œå®ç°è¿™ç§æ˜ å°„(æ½œåœ¨ç‚¹->å›¾åƒ)çš„æ¨¡å—å°±æ˜¯ GAN çš„ generatorï¼Œæˆ–è€… VAE çš„ decoderã€‚

GANã€VAE ç”Ÿæˆå›¾åƒçš„å…³é”®å°±åœ¨äºæ‰¾åˆ°ä¸€ä¸ªä½ç»´çš„ã€Œè¡¨ç¤ºæ½œåœ¨ç©ºé—´ã€(latent space of representations)ã€‚ä¸€æ—¦æ‰¾åˆ°è¿™æ ·çš„æ½œåœ¨ç©ºé—´ï¼Œä»ä¸­é‡‡æ ·ï¼Œæ˜ å°„åˆ°å›¾åƒç©ºé—´ï¼Œå°±å¯ä»¥ç”Ÿæˆå…¨æ–°çš„å›¾åƒã€‚

![å­¦ä¹ å›¾åƒçš„æ½œåœ¨å‘é‡ç©ºé—´ï¼Œå¹¶åˆ©ç”¨è¿™ä¸ªç©ºé—´æ¥é‡‡æ ·æ–°å›¾åƒ](https://tva1.sinaimg.cn/large/007S8ZIlgy1ghut6hcq7kj317g0qyti6.jpg)

GAN å’Œ VAE å­¦ä¹ çš„æ½œåœ¨ç©ºé—´æœ‰å¾ˆå¤§çš„åŒºåˆ«ï¼š

- VAE å–„äºå­¦ä¹ å…·æœ‰è‰¯å¥½ç»“æ„çš„æ½œåœ¨ç©ºé—´ï¼Œå…¶ä¸­çš„ç‰¹å®šæ–¹å‘å¯ä»¥ç¼–ç (è¡¨ç¤º)æ•°æ®ä¸­ä¸€ä¸ªæœ‰æ„ä¹‰çš„å˜åŒ–çš„è½´ã€‚
- GAN ç”Ÿæˆçš„å›¾åƒå¯ä»¥éå¸¸é€¼çœŸï¼Œä½†æ½œåœ¨ç©ºé—´ç¼ºä¹è‰¯å¥½çš„ç»“æ„ã€æ²¡æœ‰è¶³å¤Ÿçš„è¿ç»­æ€§ã€‚


### æ¦‚å¿µå‘é‡

æ¦‚å¿µå‘é‡(concept vector)ï¼šç»™å®šä¸€ä¸ªè¡¨ç¤ºçš„æ½œåœ¨ç©ºé—´æˆ–ä¸€ä¸ªåµŒå…¥ç©ºé—´ï¼Œç©ºé—´ä¸­çš„ç‰¹å®šæ–¹å‘å¯èƒ½è¡¨ç¤ºåŸå§‹æ•°æ®ä¸­æœ‰æ„ä¹‰çš„å˜åŒ–è½´ã€‚ä¾‹å¦‚å¯¹äºå›¾åƒï¼Œäººè„¸å›¾åƒçš„æ½œåœ¨ç©ºé—´ä¸­å¯èƒ½å­˜åœ¨ä¸€ä¸ªä»£è¡¨ã€Œå¾®ç¬‘ã€è¿™ä¸ªæ¦‚å¿µçš„å‘é‡(ç§°ä¸ºå¾®ç¬‘å‘é‡ï¼Œsmile vector)ï¼šå¯¹äºä»£è¡¨æŸå¼ äººè„¸çš„æ½œåœ¨ç‚¹ zï¼Œz+s å°±æ˜¯åŒä¸€å¼ äººè„¸é¢å¸¦å¾®ç¬‘çš„è¡¨ç¤ºã€‚

æ‰¾åˆ°äº†è¿™æ ·çš„ä¸€äº›æ¦‚å¿µå‘é‡ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥ç”¨è¿™ç§æ–¹æ³•æ¥ç¼–è¾‘å›¾åƒäº†ï¼šå°†å›¾åƒæŠ•å°„åˆ°æ½œåœ¨ç©ºé—´ï¼Œå’Œæ¦‚å¿µå‘é‡åšè¿ç®—æ¥ç§»åŠ¨å…¶è¡¨ç¤ºï¼Œç„¶åå†è§£ç åˆ°å›¾åƒç©ºé—´ï¼Œå°±å¯ä»¥æ”¹å˜å›¾åƒä¸­çš„æŸä¸€æ¦‚å¿µäº†â€”â€”æ¯”å¦‚å¾®ç¬‘ç¨‹åº¦ï¼š

![å¾®ç¬‘å‘é‡](https://tva1.sinaimg.cn/large/007S8ZIlgy1ghuynp3pb9j31880kux67.jpg)


### å˜åˆ†è‡ªç¼–ç å™¨

è‡ªç¼–ç å™¨æ˜¯ä¸€ç§ç½‘ç»œç±»å‹ï¼Œæ¥æ”¶ä¸€å¼ å›¾åƒï¼Œé€šè¿‡ encoder æ¨¡å—å°†å…¶æ˜ å°„åˆ°ã€Œæ½œåœ¨ç©ºé—´ã€ï¼Œç„¶åå†é€šè¿‡ decoder æ¨¡å—å°†å…¶è§£ç æˆä¸åŸå§‹å›¾åƒå°ºå¯¸ç›¸åŒçš„è¾“å‡ºã€‚è¿™ä¸œè¥¿è®­ç»ƒæ—¶çš„ç›®æ ‡æ˜¯ä½¿è¾“å‡ºå’Œè¾“å…¥ç›¸åŒï¼Œæ‰€ä»¥æˆ‘ä»¬æŠŠè¾“å…¥ã€è¾“å‡ºç”¨åŒä¸€å¼ å›¾ç‰‡ã€‚æ‰€ä»¥è‡ªç¼–ç å™¨å­¦ä¹ çš„æ˜¯å¯¹åŸå§‹è¾“å…¥è¿›è¡Œé‡æ–°æ„å»ºã€‚

é€šè¿‡å¯¹ç¼–ç (ç¼–ç å™¨çš„è¾“å‡º)æ–½åŠ é™åˆ¶ï¼Œå¯ä»¥è®©è‡ªç¼–ç å™¨å­¦åˆ°æœ‰ç”¨çš„æ•°æ®æ½œåœ¨è¡¨ç¤ºã€‚æ¯”å¦‚é™åˆ¶ç¼–ç è¦ä½ç»´å¹¶ä¸”æ˜¯ç¨€ç–çš„ï¼Œè¿™æ ·ç¼–ç å™¨å°±å¯ä»¥å°†è¾“å…¥æ•°æ®å‹ç¼©ä¸ºæ›´å°‘äºŒè¿›åˆ¶ä½çš„ä¿¡æ¯ï¼š

![è‡ªç¼–ç å™¨:å°†è¾“å…¥xæ˜ å°„ä¸ºå‹ç¼©è¡¨ç¤ºï¼Œç„¶åå†å°†å…¶è§£ç ä¸ºxâ€™](https://tva1.sinaimg.cn/large/007S8ZIlgy1ghuz8fj78aj31ao0dwtbk.jpg)

å˜åˆ†è‡ªç¼–ç å™¨ VAEï¼Œæ˜¯ä¸€ç§ç°ä»£åŒ–çš„è‡ªç¼–ç å™¨ã€‚å®ƒæ˜¯ä¸€ç§ç”Ÿæˆå¼æ¨¡å‹ï¼Œç‰¹åˆ«åšåˆ©ç”¨æ¦‚å¿µå‘é‡è¿›è¡Œå›¾åƒç¼–è¾‘çš„ä»»åŠ¡ã€‚æ¯”èµ·ç»å…¸è‡ªç¼–ç å™¨ï¼ŒVAE å¯ä»¥å­¦ä¹ æ›´è¿ç»­çš„ã€é«˜åº¦ç»“æ„åŒ–çš„æ½œåœ¨ç©ºé—´ã€‚

VAE ä¸æ˜¯å°†è¾“å…¥å›¾åƒå‹ç¼©æˆæ½œåœ¨ç©ºé—´ä¸­çš„å›ºå®šç¼–ç ï¼Œè€Œæ˜¯å°†å›¾åƒè½¬æ¢ä¸ºç»Ÿè®¡åˆ†å¸ƒçš„å‚æ•°â€”â€”å¹³å‡å€¼å’Œæ–¹å·®ã€‚VAE è§£ç çš„æ—¶å€™åˆ©ç”¨å¹³å‡å€¼å’Œæ–¹å·®ï¼Œä»åˆ†å¸ƒä¸­éšæœºé‡‡æ ·ä¸€ä¸ªå…ƒç´ ï¼Œå¹¶å°†è¿™ä¸ªå…ƒç´ è§£ç åˆ°åŸå§‹è¾“å…¥ã€‚æ‰€ä»¥ VAE çš„ç¼–ç /è§£ç è¿‡ç¨‹æ˜¯æœ‰ä¸€å®šçš„éšæœºæ€§çš„ã€‚

è¿™ä¸ªè¿‡ç¨‹çš„éšæœºæ€§æé«˜äº† VAE æ½œåœ¨ç©ºé—´çš„ç¨³å¥æ€§ï¼šVAE éœ€ä¿è¯æ½œåœ¨ç©ºé—´é‡‡æ ·çš„æ¯ä¸ªç‚¹éƒ½èƒ½è§£ç ä¸ºæœ‰æ•ˆçš„è¾“å‡ºï¼Œè¿™è¿«ä½¿æ½œåœ¨ç©ºé—´çš„ä»»ä½•ä½ç½®éƒ½å¯¹åº”æœ‰æ„ä¹‰çš„è¡¨ç¤ºã€‚

![VAE å°†ä¸€å¼ å›¾åƒæ˜ å°„ä¸ºä¸¤ä¸ªå‘é‡ z_mean å’Œ z_log_varï¼ŒäºŒè€…å®šä¹‰äº†æ½œåœ¨ ç©ºé—´ä¸­çš„ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œç”¨äºé‡‡æ ·ä¸€ä¸ªæ½œåœ¨ç‚¹å¹¶å¯¹å…¶è¿›è¡Œè§£ç ](https://tva1.sinaimg.cn/large/007S8ZIlgy1ghuzfuik3jj31bi0piah3.jpg)

ä¸Šå›¾å±•ç°äº† VAE çš„å·¥ä½œåŸç†ï¼š

1. Encoder æ¨¡å—å°†è¾“å…¥æ ·æœ¬ `input_img` è½¬æ¢ä¸ºè¡¨ç¤ºæ½œåœ¨ç©ºé—´ä¸­çš„å‚æ•° `z_mean` å’Œ `z_log_variance`;
2. ä»è¿™ä¸ªæ½œåœ¨æ­£æ€åˆ†å¸ƒä¸­éšæœºé‡‡æ ·ä¸€ä¸ªç‚¹ z: `z = z_mean + exp(z_log_variance) * epsilon`ï¼Œå…¶ä¸­ epsilon æ˜¯å–å€¼å¾ˆå°çš„éšæœºå¼ é‡;
3. Decoder æ¨¡å—å°†è¿™ä¸ªæ½œåœ¨ç‚¹æ˜ å°„å›åŸå§‹è¾“å…¥å›¾åƒã€‚

epsilon æ˜¯éšæœºçš„ï¼Œæ‰€ä»¥éœ€è¦ä¸ input_img ç¼–ç çš„æ½œåœ¨ä½ç½®(z-mean)é è¿‘çš„æ¯ä¸ªç‚¹éƒ½èƒ½è¢«è§£ç ä¸ºä¸ input_img ç±»ä¼¼çš„å›¾åƒï¼Œè¿™ä¸ªæ€§è´¨è¿«ä½¿æ½œåœ¨ç©ºé—´èƒ½å¤Ÿè¿ç»­åœ°æœ‰æ„ä¹‰ï¼šæ½œåœ¨ç©ºé—´ä¸­ä»»æ„ä¸¤ä¸ªç›¸é‚»çš„ç‚¹éƒ½ä¼šè¢«è§£ç ä¸ºé«˜åº¦ç›¸ä¼¼çš„å›¾åƒã€‚è¿ç»­æ€§ä»¥åŠæ½œåœ¨ç©ºé—´çš„ä½ç»´åº¦ï¼Œåˆè¿«ä½¿æ½œåœ¨ç©ºé—´ä¸­çš„æ¯ä¸ªæ–¹å‘éƒ½è¡¨ç¤ºæ•°æ®ä¸­ä¸€ä¸ªæœ‰æ„ä¹‰çš„å˜åŒ–è½´ï¼Œè¿™æ ·å°±å¯ä»¥é€šè¿‡æ¦‚å¿µå‘é‡æ¥è¿›è¡Œæ“ä½œã€‚

ç”¨ Keras å®ç° VAE çš„ä¼ªä»£ç å¦‚ä¸‹ï¼š

```python
z_mean, z_log_variance = encoder(input_img)
z = z_mean + exp(z_log_variance) * epsilon
reconstructed_img = decoder(z)
model = Model(input_img, reconstruced_img)
```

è®­ç»ƒ VAE éœ€è¦ä¸¤ä¸ªæŸå¤±å‡½æ•°ï¼š

- é‡æ„æŸå¤±(reconstruction loss)ï¼šä½¿è§£ç åçš„æ ·æœ¬åŒ¹é…åˆå§‹è¾“å…¥;
- æ­£åˆ™åŒ–æŸå¤±(regularization loss)ï¼šä½¿æ½œåœ¨ç©ºé—´å…·æœ‰è‰¯å¥½ç»“æ„ï¼ˆè¿ç»­æ€§ã€æ¦‚å¿µå‘é‡å¯ç”¨æ€§ï¼‰ï¼ŒåŒæ—¶ä¹Ÿé™ä½åœ¨è®­ç»ƒæ•°æ®ä¸Šçš„è¿‡æ‹Ÿåˆ;


æˆ‘ä»¬å…·ä½“å®ç°ç¼–ç å™¨(encoder)ç½‘ç»œï¼šé€šè¿‡ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œå°†è¾“å…¥å›¾åƒ x æ˜ å°„ä¸ºä¸¤ä¸ªå‘é‡ z_mean å’Œ z_log_varã€‚


```python
# ä¸ä½¿ç”¨åŠæ—¶æ‰§è¡Œæ¨¡å¼

import tensorflow as tf

tf.compat.v1.disable_eager_execution()
```


```python
# VAE ç¼–ç å™¨ç½‘ç»œ

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import backend as K
from tensorflow.keras.models import Model
import numpy as np

img_shape = (28, 28, 1)
batch_size = 16
latent_dim = 2    # æ½œåœ¨ç©ºé—´çš„ç»´åº¦ï¼š2Då¹³é¢

input_img = keras.Input(shape=img_shape)
x = layers.Conv2D(32, 3, padding='same', activation='relu')(input_img)
x = layers.Conv2D(64, 3, padding='same', activation='relu', strides=(2, 2))(x)
x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)
x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)

shape_before_flattening = K.int_shape(x)

x = layers.Flatten()(x)
x = layers.Dense(32, activation='relu')(x)

z_mean = layers.Dense(latent_dim)(x)
z_log_var = layers.Dense(latent_dim)(x)

```

æ¥ä¸‹æ¥çš„ä»£ç å°†ä½¿ç”¨ z_mean å’Œ z_log_var æ¥ç”Ÿæˆï¼ˆé‡‡æ ·ï¼‰ä¸€ä¸ªæ½œåœ¨ç©ºé—´ç‚¹ zã€‚


```python
# æ½œåœ¨ç©ºé—´é‡‡æ ·çš„å‡½æ•°

def sampling(args):
    z_mean, z_log_var = args
    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),
                              mean=0.,
                              stddev=1.)
    return z_mean + K.exp(z_log_var) * epsilon

z = layers.Lambda(sampling)([z_mean, z_log_var])    # å°è£…ä¸ºå±‚
```

ç„¶åæ˜¯è§£ç å™¨çš„å®ç°ï¼šå°†å‘é‡ z çš„å°ºå¯¸è°ƒæ•´ä¸ºå›¾åƒå¤§å°ï¼Œç„¶åä½¿ç”¨å‡ ä¸ªå·ç§¯å±‚æ¥å¾—åˆ°æœ€ç»ˆçš„å›¾åƒè¾“å‡ºã€‚


```python
# VAE è§£ç å™¨ç½‘ç»œ

decoder_input = layers.Input(K.int_shape(z)[1:])
x = layers.Dense(np.prod(shape_before_flattening[1:]),
                 activation='relu')(decoder_input)
x = layers.Reshape(shape_before_flattening[1:])(x)
x = layers.Conv2DTranspose(32, 3,
                           padding='same',
                           activation='relu',
                           strides=(2, 2))(x)
x = layers.Conv2D(1, 3,
                  padding='same',
                  activation='sigmoid')(x)

decoder = Model(decoder_input, x)

z_decoded = decoder(z)
```

VAE è¦ç”¨ä¸¤ä¸ªæŸå¤±ï¼Œæ‰€ä»¥ä¸èƒ½ç›´æ¥å†™æˆ `loss(input, target)`ï¼Œæˆ‘ä»¬éœ€è¦ç¼–å†™ä¸€ä¸ªè‡ªå®šä¹‰å±‚ï¼Œåœ¨å…¶ä¸­ä½¿ç”¨å†…ç½®çš„ `add_loss` æ–¹æ³•æ¥åˆ›å»ºéœ€è¦çš„æŸå¤±ã€‚


```python
# ç”¨äºè®¡ç®— VAE æŸå¤±çš„è‡ªå®šä¹‰å±‚

class CustomVariationalLayer(keras.layers.Layer):
    def vae_loss(self, x, z_decoded):
        x = K.flatten(x)
        z_decoded = K.flatten(z_decoded)
        
        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)
        kl_loss = -5e-4 * K.mean(
            1 + z_log_var - K.square(z_mean) - K.exp(z_log_var),
            axis=-1)
        return K.mean(xent_loss + kl_loss)
    
    def call(self, inputs):
        x = inputs[0]
        z_decoded = inputs[1]
        
        loss = self.vae_loss(x, z_decoded)
        self.add_loss(loss, inputs=inputs)
        
        return x
    
y = CustomVariationalLayer()([input_img, z_decoded])
```

æœ€åï¼Œå°†æ¨¡å‹å®ä¾‹åŒ–å¹¶å¼€å§‹è®­ç»ƒã€‚ç”±äºæˆ‘ä»¬çš„æŸå¤±ä»¥åŠåŒ…å«åœ¨è‡ªå®šä¹‰å±‚é‡Œé¢äº†ï¼Œæ‰€ä»¥ç¼–è¯‘æ—¶æ— é¡»æŒ‡å®šå¤–éƒ¨æŸå¤±(`loss=None`)ï¼Œæ‰€ä»¥ä¹Ÿå°±ä¸éœ€è¦å¤–éƒ¨æŒ‡å®šçš„ç›®æ ‡æ•°æ®(`y=None`)ã€‚

è¿™é‡Œæˆ‘ä»¬ç”¨ MNIST å»è®­ç»ƒå®ƒï¼Œä¹Ÿå°±æ˜¯ç”Ÿæˆæ‰‹å†™æ•°å­—çš„æ½œåœ¨ç©ºé—´ã€‚


```python
from tensorflow.keras.datasets import mnist

vae = Model(input_img, y)
vae.compile(optimizer='rmsprop', loss=None)
vae.summary()

(x_train, _), (x_test, y_test) = mnist.load_data()

x_train = x_train.astype('float32') / 255.
x_train = x_train.reshape(x_train.shape + (1,))

x_test = x_test.astype('float32') / 255.
x_test = x_test.reshape(x_test.shape + (1,))

vae.fit(x=x_train, y=None,
        shuffle=True,
        epochs=10,
        batch_size=batch_size,
        validation_data=(x_test, None))
```

    WARNING:tensorflow:Output custom_variational_layer_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_1.
    Model: "functional_7"
    __________________________________________________________________________________________________
    Layer (type)                    Output Shape         Param #     Connected to                     
    ==================================================================================================
    input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            
    __________________________________________________________________________________________________
    conv2d_5 (Conv2D)               (None, 28, 28, 32)   320         input_1[0][0]                    
    __________________________________________________________________________________________________
    conv2d_6 (Conv2D)               (None, 14, 14, 64)   18496       conv2d_5[0][0]                   
    __________________________________________________________________________________________________
    conv2d_7 (Conv2D)               (None, 14, 14, 64)   36928       conv2d_6[0][0]                   
    __________________________________________________________________________________________________
    conv2d_8 (Conv2D)               (None, 14, 14, 64)   36928       conv2d_7[0][0]                   
    __________________________________________________________________________________________________
    flatten_1 (Flatten)             (None, 12544)        0           conv2d_8[0][0]                   
    __________________________________________________________________________________________________
    dense_4 (Dense)                 (None, 32)           401440      flatten_1[0][0]                  
    __________________________________________________________________________________________________
    dense_5 (Dense)                 (None, 2)            66          dense_4[0][0]                    
    __________________________________________________________________________________________________
    dense_6 (Dense)                 (None, 2)            66          dense_4[0][0]                    
    __________________________________________________________________________________________________
    lambda_1 (Lambda)               (None, 2)            0           dense_5[0][0]                    
                                                                     dense_6[0][0]                    
    __________________________________________________________________________________________________
    functional_5 (Functional)       (None, 28, 28, 1)    56385       lambda_1[0][0]                   
    __________________________________________________________________________________________________
    custom_variational_layer_1 (Cus (None, 28, 28, 1)    0           input_1[0][0]                    
                                                                     functional_5[0][0]               
    ==================================================================================================
    Total params: 550,629
    Trainable params: 550,629
    Non-trainable params: 0
    __________________________________________________________________________________________________
    Train on 60000 samples, validate on 10000 samples
    Epoch 1/10
    60000/60000 [==============================] - 219s 4ms/sample - loss: 0.2173 - val_loss: 0.2016
    ...
    Epoch 10/10
    60000/60000 [==============================] - 234s 4ms/sample - loss: 0.1840 - val_loss: 0.1826



è®­ç»ƒå¥½æ¨¡å‹ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ decoder å°†ä»»æ„æ½œåœ¨ç©ºé—´ä¸­çš„å‘é‡è½¬æ¢ä¸ºå›¾åƒã€‚


```python
# ä»æ½œåœ¨ç©ºé—´ä¸­é‡‡æ ·ä¸€ç»„ç‚¹ï¼Œè§£ç ä¸ºå›¾åƒ

import matplotlib.pyplot as plt
from scipy.stats import norm

n = 15    # æ˜¾ç¤º 15x15ä¸ªæ•°
digit_size = 28
figure = np.zeros((digit_size * n, digit_size * n))

grid_x = norm.ppf(np.linspace(0.05, 0.95, n))  # ppf å‡½æ•°å¯¹çº¿æ€§åˆ†éš”çš„åæ ‡è¿›è¡Œå˜æ¢ï¼Œä»¥ç”Ÿæˆæ½œåœ¨å˜é‡ z çš„å€¼
grid_y = norm.ppf(np.linspace(0.05, 0.95, n))

for i, yi in enumerate(grid_x):
    for j, xi in enumerate(grid_y):
        z_simple = np.array([[xi, yi]])
        z_simple = np.tile(z_simple, batch_size).reshape(batch_size, 2)
        x_decoded = decoder.predict(z_simple, batch_size=batch_size)
        digit = x_decoded[0].reshape(digit_size, digit_size)
        figure[i * digit_size: (i + 1) * digit_size,
               j * digit_size: (j + 1) * digit_size] = digit

plt.figure(figsize=(10, 10))
plt.imshow(figure, cmap='Greys_r')
plt.show()
```


![png](https://tva1.sinaimg.cn/large/007S8ZIlgy1gi0w0g9euhj30gb0g2dib.jpg)


ä¹¦ä¸Šåˆ°è¿™é‡Œå°±ç»“æŸäº†ï¼Œå¹¶æ²¡æœ‰æ·±å…¥å†™ä¹‹å‰æåˆ°çš„æ¦‚å¿µå‘é‡çš„åº”ç”¨ğŸ˜‚ï¼Œå¥½é—æ†¾å•Šã€‚
